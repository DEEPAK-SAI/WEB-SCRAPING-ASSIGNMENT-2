{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7577cafc",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c66d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver') # Webdriver for linux\n",
    "time.sleep(4)\n",
    "\n",
    "# opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f818e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job search bar\n",
    "search_field_deisgnation = driver.find_element_by_class_name('suggestor-input') # job search bar\n",
    "search_field_deisgnation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df525bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering location bangalore in location search bar\n",
    "search_field_designation = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input') # job search bar\n",
    "search_field_designation.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57418597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button\n",
    "search_button = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "time.sleep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac9c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "company_names = []\n",
    "locations_list = []\n",
    "experience_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4732c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst / Business Analyst',\n",
       " 'Data Analyst / Business Analyst',\n",
       " 'data analyst/ data analytics / Business analyst- SQL/Python/SAS',\n",
       " 'Senior Data Analyst',\n",
       " 'Sr Data Analyst II',\n",
       " 'Business analyst + data Analysis',\n",
       " 'Business analyst + data Analysis',\n",
       " 'Data Analyst - Alteryx',\n",
       " 'Consultant - Data Analyst',\n",
       " 'Senior Business Analyst - Data Sciences and Advanced Analytics']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the job-titles\n",
    "title_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# Extracting text of job titles\n",
    "for i in range(0, 10):\n",
    "    job_titles.append(title_tags[i].text)\n",
    "\n",
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e574b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['METRO Cash & Carry',\n",
       " 'METRO Cash & Carry',\n",
       " 'Leading US MNC into Analytics',\n",
       " 'Flipkart',\n",
       " 'IHS Markit',\n",
       " 'Anlage Infotech (I) Pvt. Ltd.',\n",
       " 'Anlage Infotech (I) Pvt. Ltd.',\n",
       " 'Capco',\n",
       " 'Flipkart',\n",
       " 'Vmware']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract company name tags\n",
    "company_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "# Getting text from the data \n",
    "for i in range(0, 10):\n",
    "    company_names.append(company_tags[i].text)\n",
    "\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5368c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting experience location\n",
    "location = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span[1]')\n",
    "\n",
    "# Getting text from extracted data\n",
    "for i in range(0, 10):\n",
    "    locations_list.append(location[i].text)\n",
    "locations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d38c6a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-6 Yrs',\n",
       " '5-10 Yrs',\n",
       " '5-10 Yrs',\n",
       " '4-7 Yrs',\n",
       " '1-3 Yrs',\n",
       " '3-7 Yrs']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract all the tags having the experience required data\n",
    "experience_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "for i in range(0, 10):\n",
    "    experience_list.append(experience_tags[i].text)\n",
    "experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062c6911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles))\n",
    "print(len(company_names))\n",
    "print(len(locations_list))\n",
    "print(len(experience_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5c4f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_titles</th>\n",
       "      <th>company_names</th>\n",
       "      <th>locations_list</th>\n",
       "      <th>experience_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Data Analyst II</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>IHS Markit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business analyst + data Analysis</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business analyst + data Analysis</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Anlage Infotech (I) Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - Alteryx</td>\n",
       "      <td>Capco</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Business Analyst - Data Sciences and Ad...</td>\n",
       "      <td>Vmware</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vmware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_titles  \\\n",
       "0                    Data Analyst / Business Analyst   \n",
       "1                    Data Analyst / Business Analyst   \n",
       "2  data analyst/ data analytics / Business analys...   \n",
       "3                                Senior Data Analyst   \n",
       "4                                 Sr Data Analyst II   \n",
       "5                   Business analyst + data Analysis   \n",
       "6                   Business analyst + data Analysis   \n",
       "7                             Data Analyst - Alteryx   \n",
       "8                          Consultant - Data Analyst   \n",
       "9  Senior Business Analyst - Data Sciences and Ad...   \n",
       "\n",
       "                   company_names  \\\n",
       "0             METRO Cash & Carry   \n",
       "1             METRO Cash & Carry   \n",
       "2  Leading US MNC into Analytics   \n",
       "3                       Flipkart   \n",
       "4                     IHS Markit   \n",
       "5  Anlage Infotech (I) Pvt. Ltd.   \n",
       "6  Anlage Infotech (I) Pvt. Ltd.   \n",
       "7                          Capco   \n",
       "8                       Flipkart   \n",
       "9                         Vmware   \n",
       "\n",
       "                                      locations_list  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "5        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "6        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                 experience_list  \n",
       "0             METRO Cash & Carry  \n",
       "1             METRO Cash & Carry  \n",
       "2  Leading US MNC into Analytics  \n",
       "3                       Flipkart  \n",
       "4                     IHS Markit  \n",
       "5  Anlage Infotech (I) Pvt. Ltd.  \n",
       "6  Anlage Infotech (I) Pvt. Ltd.  \n",
       "7                          Capco  \n",
       "8                       Flipkart  \n",
       "9                         Vmware  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Fame\n",
    "df = pd.DataFrame({'job_titles' : job_titles, 'company_names' : company_names, 'locations_list' : locations_list, 'experience_list' : company_names})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9cb3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d3e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59dc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c550a016",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21088175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a7093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver') # chrome driver\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4233db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0033c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding elemen for job search bar\n",
    "search_field_designation = driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4ddd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter loaction bangalore in location search bar\n",
    "search_field_designation = driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "search_field_designation.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9c29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on search button \n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a187cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = [] \n",
    "job_location = []\n",
    "company_name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2075ac38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title\n",
    "# extract all the tags having the job_titles\n",
    "title_tags = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# extract 10 title texts \n",
    "job_title = [i.text for i in title_tags[0 : 10]]\n",
    "len(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a6e6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location\n",
    "# extract all the tags having the job_titles\n",
    "location_tags = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "# getting text from the location_tags\n",
    "job_location = [i.text for i in location_tags[0 : 10]]\n",
    "len(job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c52b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name\n",
    "# extrat all the tags having company_name\n",
    "companies_tags = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "# getting text fromt the company_name tags\n",
    "company_name = [i.text for i in companies_tags[0:10]]\n",
    "len(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd3f794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applied Data Scientist / ML Senior Engineer (P...</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Analyst - Applied Data Scientist</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyst - Applied Data Scientist</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Research Data Scientist</td>\n",
       "      <td>Mavenir</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Applied Data Scientist</td>\n",
       "      <td>Tesco Bengaluru</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist Grade12</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist / Analyst</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title       company_name  \\\n",
       "0  Applied Data Scientist / ML Senior Engineer (P...  SAP India Pvt.Ltd   \n",
       "1               Sr. Analyst - Applied Data Scientist              Tesco   \n",
       "2                 Data Scientist: Advanced Analytics                IBM   \n",
       "3            Data Scientist: Artificial Intelligence                IBM   \n",
       "4                   Analyst - Applied Data Scientist              Tesco   \n",
       "5                            Research Data Scientist            Mavenir   \n",
       "6                        Lead Applied Data Scientist    Tesco Bengaluru   \n",
       "7                      Senior Data Scientist Grade12           Flipkart   \n",
       "8                      Senior Data Scientist Grade12           Flipkart   \n",
       "9                           Data Scientist / Analyst      Deutsche Bank   \n",
       "\n",
       "          job_location  \n",
       "0  Bangalore/Bengaluru  \n",
       "1  Bangalore/Bengaluru  \n",
       "2  Bangalore/Bengaluru  \n",
       "3  Bangalore/Bengaluru  \n",
       "4  Bangalore/Bengaluru  \n",
       "5  Bangalore/Bengaluru  \n",
       "6  Bangalore/Bengaluru  \n",
       "7  Bangalore/Bengaluru  \n",
       "8  Bangalore/Bengaluru  \n",
       "9  Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame\n",
    "df = pd.DataFrame({'job_title' : job_title, 'company_name' : company_name, 'job_location' : job_location})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3538338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400361d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54a83b7b",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\u0000\u0000\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c378a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b4a2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5340de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.naukri.com')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e064d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job search bar\n",
    "search_field_designation = driver.find_element_by_class_name('suggestor-input') # job search bar\n",
    "search_field_designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4708b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking search button\n",
    "search_button = driver.find_element_by_class_name('qsbSubmit') # search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc9705bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking bangalore lcoation checkbox\n",
    "location_checkbox = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i\")\n",
    "location_checkbox.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c6e48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting 3-6 lakh lsalary checkbox\n",
    "salary_checkbox = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[2]/label/i')\n",
    "salary_checkbox.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad04dd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Analyst - Applied Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist - Internet Jobs - II',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist 1',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist II',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'AI Resident - Data Scientist']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = []\n",
    "\n",
    "# Select job title\n",
    "job_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# extract text in job_tag\n",
    "job_title = [i.text for i in job_tag[0 : 10]]\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e818c378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tesco',\n",
       " 'Truecaller',\n",
       " 'Jobs Territory',\n",
       " 'Aurigo Software Technologies Pvt Ltd',\n",
       " 'PayPal',\n",
       " 'Ashkom Media India Private Limited',\n",
       " 'Groupon',\n",
       " 'Randstad India Private Limited',\n",
       " 'Applied Materials',\n",
       " 'Shell']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = []\n",
    "\n",
    "# Extracting company names tags \n",
    "company_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "# Selecting text from company tags, top 10\n",
    "company_name = [i.text for i in company_tag[0 : 10]]\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50517561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-2 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-6 Yrs',\n",
       " '4-6 Yrs',\n",
       " '4-8 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-6 Yrs',\n",
       " '1-5 Yrs',\n",
       " '0-3 Yrs',\n",
       " '3-4 Yrs']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expereience_list = []\n",
    "\n",
    "# Extracting experience tags \n",
    "experience_tag = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "# Extracting text from experience tags\n",
    "experience_list = [i.text for i in experience_tag[0 : 10]]\n",
    "experience_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a678dbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Noida, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location = []\n",
    "\n",
    "# Selecting location by using xpath\n",
    "location_tag = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "# Extracting location text from the tag, top 10\n",
    "job_location = [i.text for i in location_tag[0:10]]\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f98a5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experience_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "730f0d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>expereience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst - Applied Data Scientist</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Truecaller</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Internet Jobs - II</td>\n",
       "      <td>Jobs Territory</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Aurigo Software Technologies Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist 1</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Groupon</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Randstad India Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AI Resident - Data Scientist</td>\n",
       "      <td>Shell</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             job_title                          company_name  \\\n",
       "0     Analyst - Applied Data Scientist                                 Tesco   \n",
       "1                Senior Data Scientist                            Truecaller   \n",
       "2  Data Scientist - Internet Jobs - II                        Jobs Territory   \n",
       "3                       Data Scientist  Aurigo Software Technologies Pvt Ltd   \n",
       "4                     Data Scientist 1                                PayPal   \n",
       "5                       Data Scientist    Ashkom Media India Private Limited   \n",
       "6                    Data Scientist II                               Groupon   \n",
       "7                       Data Scientist        Randstad India Private Limited   \n",
       "8                       Data Scientist                     Applied Materials   \n",
       "9         AI Resident - Data Scientist                                 Shell   \n",
       "\n",
       "                                        job_location expereience  \n",
       "0                                Bangalore/Bengaluru     1-2 Yrs  \n",
       "1                                Bangalore/Bengaluru     2-5 Yrs  \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...     3-6 Yrs  \n",
       "3            Bangalore/Bengaluru\\n(WFH during Covid)     4-6 Yrs  \n",
       "4                                Bangalore/Bengaluru     4-8 Yrs  \n",
       "5                         Noida, Bangalore/Bengaluru     3-6 Yrs  \n",
       "6                                Bangalore/Bengaluru     3-6 Yrs  \n",
       "7                                Bangalore/Bengaluru     1-5 Yrs  \n",
       "8                                Bangalore/Bengaluru     0-3 Yrs  \n",
       "9                                Bangalore/Bengaluru     3-4 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'job_title' : job_title, 'company_name' : company_name, 'job_location' : job_location, 'expereience' : experience_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48348d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303c156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ef9364",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7a612223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "17e177de",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver') # chrome driver\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ae8c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening flipkart.com website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a18ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the login pop up\n",
    "close_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9888d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for search bar\n",
    "search_field = driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_field.send_keys('sunglasses') # sending \"sneakers\" as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4527d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for search button \n",
    "search_button = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_button.click() # click on search button \n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b86e26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    # Finding the brand element \n",
    "    brand_tag = driver.find_elements_by_class_name(\"_2WkVRV\")\n",
    "    for i in brand_tag: # iterate through elements in brand tag\n",
    "        Brand.append(i.text) # extracting text from tag\n",
    "\n",
    "    # Finding the Product Description\n",
    "    description_tag = driver.find_elements_by_class_name('IRpwTa')\n",
    "    for i in description_tag: # iterate trhough elements in description tag\n",
    "        Product_Description.append(i.text) # extracting text from tag\n",
    "\n",
    "    # Finding Price tags\n",
    "    price_tag = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tag: # iterate through elements in price tag\n",
    "        Price.append(i.text)\n",
    "    \n",
    "    # Finding Next button element\n",
    "    next_button = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "653831cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (64)</td>\n",
       "      <td>₹287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Others Aviator Sunglasses (63)</td>\n",
       "      <td>₹5,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹3,299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product_Description  \\\n",
       "0              PIRASO           UV Protection Over-sized Sunglasses (64)   \n",
       "1             Ray-Ban                     Others Aviator Sunglasses (63)   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3              SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...   \n",
       "4            Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "..                ...                                                ...   \n",
       "95            Ray-Ban    Mirrored, UV Protection Aviator Sunglasses (58)   \n",
       "96             PIRASO          UV Protection Rectangular Sunglasses (52)   \n",
       "97  SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "98          Elligator              UV Protection Aviator Sunglasses (55)   \n",
       "99             AISLIN  UV Protection, Gradient Retro Square Sunglasse...   \n",
       "\n",
       "     Price  \n",
       "0     ₹287  \n",
       "1   ₹5,339  \n",
       "2     ₹669  \n",
       "3     ₹233  \n",
       "4     ₹589  \n",
       "..     ...  \n",
       "95  ₹3,299  \n",
       "96    ₹186  \n",
       "97    ₹145  \n",
       "98    ₹283  \n",
       "99    ₹448  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand' : Brand[0:100], \"Product_Description\" : Product_Description[0:100], 'Price' : Price[0:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "44879dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3814b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78523a84",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45ed1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b80bd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating driver and opening browser\n",
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver') # driver for ubuntu\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46dd2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up flipkart \n",
    "url = \"\"\"\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace\n",
    "\"\"\"\n",
    "driver.get(url)\n",
    "time.sleep(5) # wait till the website opens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef0f2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting \"All reviews\"\n",
    "all_reviews = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span')\n",
    "all_reviews.click() # click the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffa1855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "\n",
    "# loopin through 10 pages of review having 10 reviews in them\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # fetching rating \n",
    "    Rating_tag = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    # extracting all the rating text from the tag\n",
    "    for i in Rating_tag: # iterate throught tag\n",
    "        Rating.append(i.text) # append text to the list\n",
    "\n",
    "\n",
    "    # Fetching summary tag\n",
    "    summary_tag = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    # extracting all summary text from the summary_tag\n",
    "    for i in summary_tag: # iterate through tags\n",
    "        Review_summary.append(i.text) # appending text to the list\n",
    "    \n",
    "\n",
    "\n",
    "    # Fetching Full Review\n",
    "    review_tag = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    # extracting text from the review_tag\n",
    "    for i in review_tag: # iterate throught the elements in tag\n",
    "        Full_review.append(i.text) # appending text to list\n",
    "    \n",
    "    # Finding next button\n",
    "    next_button = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5) # wait 5seconds the next page loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0360cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5    Worth every penny   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                          Full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  i11 is worthy to buy, too much happy with the ...  \n",
       "99  What a camera .....just awesome ..you can feel...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame({'Rating' : Rating, 'Review_summary' : Review_summary, 'Full_review' : Full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d777632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb76f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6232f0e7",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e36e75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e238c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32773c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening flipkart.com\n",
    "driver.get('https://www.flipkart.com')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9874d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the login pop up\n",
    "close_button = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "close_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1ce9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for search bar\n",
    "search_field = driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_field.send_keys('sneakers') # sending \"sneakers\" as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f6f19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for search button \n",
    "search_button = driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_button.click() # click on search button "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4bd5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "Discount = []\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    # Finding the brand element \n",
    "    brand_tag = driver.find_elements_by_class_name(\"_2WkVRV\")\n",
    "    for i in brand_tag: # iterate through elements in brand tag\n",
    "        Brand.append(i.text) # extracting text from tag\n",
    "\n",
    "    # Finding the Product Description\n",
    "    description_tag = driver.find_elements_by_class_name('IRpwTa')\n",
    "    for i in description_tag: # iterate trhough elements in description tag\n",
    "        Product_Description.append(i.text) # extracting text from tag\n",
    "\n",
    "    # Finding Price tags\n",
    "    price_tag = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tag: # iterate through elements in price tag\n",
    "        Price.append(i.text)\n",
    "\n",
    "    # Selecting deiscount tag \n",
    "    discount_tag = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in discount_tag: # iterate through elements in discount tag\n",
    "            Discount.append(i.text)\n",
    "\n",
    "    # Finding Next button element\n",
    "    next_button = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f31e90a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand))\n",
    "print(len(Product_Description))\n",
    "print(len(Price))\n",
    "print(len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4796905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "015c3300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,819</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>White Sneaker For Men Sneakers For Men</td>\n",
       "      <td>₹405</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹148</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹245</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corsac</td>\n",
       "      <td>STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Figor</td>\n",
       "      <td>Casual Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹419</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹297</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>TREGGER 2.0 Sneakers For Men</td>\n",
       "      <td>₹2,939</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand                                Product_Description  \\\n",
       "0   HRX by Hrithik Roshan                                   Sneakers For Men   \n",
       "1                 Numenzo             White Sneaker For Men Sneakers For Men   \n",
       "2                URBANBOX                          Sneakers Sneakers For Men   \n",
       "3                  BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "4                  corsac  STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...   \n",
       "..                    ...                                                ...   \n",
       "95                  Figor              Casual Sneaker Shoes Sneakers For Men   \n",
       "96                 Labbin                                   Sneakers For Men   \n",
       "97               ASTEROID  Original Luxury Branded Fashionable Men's Casu...   \n",
       "98                   aadi                                   Sneakers For Men   \n",
       "99        U.S. POLO ASSN.                       TREGGER 2.0 Sneakers For Men   \n",
       "\n",
       "     Price Discount  \n",
       "0   ₹1,819  49% off  \n",
       "1     ₹405  68% off  \n",
       "2     ₹148  85% off  \n",
       "3     ₹245  81% off  \n",
       "4     ₹449  70% off  \n",
       "..     ...      ...  \n",
       "95    ₹599  58% off  \n",
       "96    ₹419  77% off  \n",
       "97    ₹449  70% off  \n",
       "98    ₹297  36% off  \n",
       "99  ₹2,939  60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand' : Brand[0 : 100], 'Product_Description' : Product_Description[0 : 100], 'Price' : Price[0 : 100], 'Discount' : Discount[0 : 100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9260b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d351ca4",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d1ccd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the required librrires\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80ec7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver fro chrome\n",
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver')\n",
    "time.sleep(2) # Wait for browser to open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c9608ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening https://www.myntra.com/shoes in chrome using driver\n",
    "driver.get('https://www.myntra.com/shoes')\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1386ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting black color\n",
    "black_color = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "\n",
    "# Clicking on checkbox\n",
    "black_color.click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dbf02981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting price checkbox\n",
    "price_range_checkbox = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "\n",
    "# Clicking on checkbox\n",
    "price_range_checkbox.click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93fd5c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "price_tag = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "price = []\n",
    "for i in price_tag:\n",
    "    price.append(i.text)\n",
    "print(len(price))\n",
    "\n",
    "Description = []\n",
    "description_tag = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "for i in description_tag: # iterate through items in descripttion tag list\n",
    "    Description.append(i.text) \n",
    "print(len(Description))\n",
    "\n",
    "Brand = []\n",
    "brand_tag = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "# Extracting brand name\n",
    "for i in brand_tag:\n",
    "    Brand.append(i.text)\n",
    "print(len(Brand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e24a43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Description = []\n",
    "Price = []\n",
    "\n",
    "for i in range(0,4): # iterate 3 time to get 100+ data\n",
    "    # Finding all the brand tags\n",
    "    brand_tag = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    # Extracting brand name\n",
    "    for i in brand_tag:\n",
    "        Brand.append(i.text)\n",
    "\n",
    "    # Finding all the description tags\n",
    "    description_tag = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for i in description_tag: # iterate through items in descripttion tag list\n",
    "        Description.append(i.text) # append text to Description list\n",
    "\n",
    "    # Fetching all the price elements\n",
    "    price_tag = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for i in price_tag: # iterate through items in price_tag list\n",
    "        Price.append(i.text)\n",
    "\n",
    "    # Next button element\n",
    "    next_button = driver.find_element_by_xpath('//li[@class=\"pagination-next\"]')\n",
    "    next_button.click() # click on next button\n",
    "    time.sleep(4) # wait till the page loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db19384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8c1143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Winflo 7 Running Shoes</td>\n",
       "      <td>Rs. 7195Rs. 7995(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Vantage 2 Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>Rs. 8920Rs. 10495(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Loafers</td>\n",
       "      <td>Rs. 11899Rs. 16999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Embellished Wedge Sandals</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Women Textured Mules</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Women Colourblocked Leather Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                           Description  \\\n",
       "0           Nike            Men Winflo 7 Running Shoes   \n",
       "1       Skechers            Men Max Cushioning Running   \n",
       "2   UNDER ARMOUR           Men Vantage 2 Running Shoes   \n",
       "3           ALDO                          Men Sneakers   \n",
       "4           Nike        Women React MR 3 Running Shoes   \n",
       "..           ...                                   ...   \n",
       "95     J.FONTINI            Men Leather Formal Loafers   \n",
       "96     Cole Haan                 Women Leather Loafers   \n",
       "97          ALDO             Embellished Wedge Sandals   \n",
       "98       Bugatti                  Women Textured Mules   \n",
       "99          FILA  Women Colourblocked Leather Sneakers   \n",
       "\n",
       "                          price  \n",
       "0     Rs. 7195Rs. 7995(10% OFF)  \n",
       "1     Rs. 7199Rs. 8999(20% OFF)  \n",
       "2                      Rs. 7999  \n",
       "3                      Rs. 9999  \n",
       "4    Rs. 8920Rs. 10495(15% OFF)  \n",
       "..                          ...  \n",
       "95                     Rs. 7490  \n",
       "96  Rs. 11899Rs. 16999(30% OFF)  \n",
       "97                     Rs. 7999  \n",
       "98                     Rs. 7999  \n",
       "99                     Rs. 9999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating data frame by passing dictionary \n",
    "df = pd.DataFrame({'Brand' : Brand[0 : 100], 'Description' : Description[0 : 100] , 'price' : Price[0 : 100] })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5ef10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a7e80d3",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ccb56555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "09bf88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver \n",
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b53bf4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open amazon website\n",
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f78c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search input field tag\n",
    "search_field = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "# Send \"laptop\" as key to input field\n",
    "search_field.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "580e2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search button element\n",
    "search_button = driver.find_element_by_xpath('//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "# Clicking on search button\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9c0ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor checkbox\n",
    "checkbox = driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label/i')\n",
    "#click on checkbox\n",
    "checkbox.click()\n",
    "\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d47ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Ratings = []\n",
    "Price = []\n",
    "\n",
    "# Fetching title tag \n",
    "title_tag = driver.find_elements_by_xpath('//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "# Extracting text from title tag\n",
    "for i in title_tag: # iterating through title tag\n",
    "    Title.append(i.text) # appending text to title list\n",
    "\n",
    "# Fetching price tag\n",
    "price_tag = driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tag: # iterating through price tag elements\n",
    "    Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93dffd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Predator Helios 300 11th Gen Intel Core i...</td>\n",
       "      <td>1,69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>58,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td>77,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>86,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS Zenbook 14X OLED Space Edition, 14\" (35.5...</td>\n",
       "      <td>1,34,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 11th Gen Intel Core i7 Processor 1...</td>\n",
       "      <td>99,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 15 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>92,400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price\n",
       "0  Acer Predator Helios 300 11th Gen Intel Core i...  1,69,990\n",
       "1  Mi Notebook Horizon Edition 14 Intel Core i7-1...    58,999\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...    57,490\n",
       "3  Mi Notebook Ultra 3.2K Resolution Display Inte...    77,999\n",
       "4  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...    86,990\n",
       "5  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    86,900\n",
       "6  Samsung Galaxy Book2 Intel 12th Gen core i7 39...    79,990\n",
       "7  ASUS Zenbook 14X OLED Space Edition, 14\" (35.5...  1,34,990\n",
       "8  HP Pavilion 11th Gen Intel Core i7 Processor 1...    99,500\n",
       "9  HP Pavilion 15 12th Gen Intel Core i7 16GB SDR...    92,400"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title' : Title[0:10], 'Price' : Price[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9c483a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4eee34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a59bede3",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bc353255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d68b0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ea4204d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up naukri.com website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8cd97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select job option\n",
    "job = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "job.click() # click on job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b13cc517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input field \n",
    "input_field = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "input_field.send_keys('Data Scientis') # Send Data Scientist as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2dff891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select search button\n",
    "search_button = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "search_button.click() # Click on search button\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7963c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select location dropdown\n",
    "location_dropdown = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]')\n",
    "location_dropdown.click() # Click on locaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "18de3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering location as Noida\n",
    "search_field = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "search_field.send_keys(\"Noida\") # Sending input as Noida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0e40f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noida radio button\n",
    "radio_button = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "radio_button.click() # Click on radio button\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7d89209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "No_of_days = []\n",
    "Rating = []\n",
    "\n",
    "# company_name tag\n",
    "name_tag = driver.find_elements_by_xpath('//a[@class=\"title noclick\"]')\n",
    "for i in name_tag:# Iterate through items in name tag\n",
    "    company_name.append(i.text) # append text to company_name\n",
    "    \n",
    "# No of days ago posted\n",
    "days_tag = driver.find_elements_by_xpath('//div[@class=\"other-info\"]/span[1]')\n",
    "for i in days_tag: # Iterate through items in days tag\n",
    "    No_of_days.append(i.text) # append text to No_of_days list\n",
    "    \n",
    "# Ratings \n",
    "rating_tag = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "for i in rating_tag: # Iterate through items of rating tag\n",
    "    Rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eca663c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "141d27f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Applied Data Scientist / ML Senior Engineer (P...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>20hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4.1</td>\n",
       "      <td>21hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4.1</td>\n",
       "      <td>21hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4.1</td>\n",
       "      <td>21hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Applied Data Scientist</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18hr ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company_name Rating  \\\n",
       "0  Applied Data Scientist / ML Senior Engineer (P...    4.4   \n",
       "1            Data Scientist: Artificial Intelligence    4.1   \n",
       "2            Data Scientist: Artificial Intelligence    4.1   \n",
       "3            Data Scientist: Artificial Intelligence    4.1   \n",
       "4                                     Data Scientist    4.1   \n",
       "5                        Lead Applied Data Scientist    4.1   \n",
       "6            Data Scientist: Artificial Intelligence    4.1   \n",
       "7            Data Scientist: Artificial Intelligence    4.1   \n",
       "8            Data Scientist: Artificial Intelligence    4.1   \n",
       "9            Data Scientist: Artificial Intelligence    4.1   \n",
       "\n",
       "  No. of days ago when job was posted  \n",
       "0                            20hr ago  \n",
       "1                            21hr ago  \n",
       "2                            21hr ago  \n",
       "3                            21hr ago  \n",
       "4                              3d ago  \n",
       "5                            18hr ago  \n",
       "6                              4d ago  \n",
       "7                              4d ago  \n",
       "8                              4d ago  \n",
       "9                              4d ago  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "df = pd.DataFrame({'company_name' : company_name, 'Rating' : Rating, 'No. of days ago when job was posted' : No_of_days })\n",
    "df # Dispalying dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972e108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c95ee76",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1baeed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d047edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver open browser\n",
    "driver = webdriver.Chrome(r'/usr/bin/chromedriver')\n",
    "time.sleep(2) # wait till the browser loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e681645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening up https://www.ambitionbox.com/\n",
    "driver.get('https://www.ambitionbox.com/') # open ambition box website\n",
    "time.sleep(5) # wati till the page loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca647592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Salaries option\n",
    "salaries = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "salaries.click() # click on salaries\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "537eff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input field \n",
    "input_field = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div/div/div/div[1]/span/input')\n",
    "input_field.send_keys('Data Scientist') # Send Data Scientist as input\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27729416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Data Scientist option\n",
    "ds = driver.find_element_by_xpath('//p[@class=\"tt_text\"]')\n",
    "ds.click()# click on Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88ae58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search button\n",
    "search_button = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div/div/div/button')\n",
    "search_button.click() # click on search button\n",
    "time.sleep(5) # wait 5 seconds for the pag to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "615d0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "total_salary_record = []\n",
    "average_salary = []\n",
    "minimum_salary = []\n",
    "maximum_salary = []\n",
    "experience_required = []\n",
    "\n",
    "# Company name\n",
    "name_tag = driver.find_elements_by_xpath('//div[@class=\"name\"]/a')\n",
    "for i in name_tag:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "# Total salary record\n",
    "total_tag = driver.find_elements_by_xpath('//div[@class=\"name\"]/span')\n",
    "for i in total_tag:\n",
    "    total_salary_record.append(i.text)\n",
    "\n",
    "# Experience required\n",
    "experience_tag = driver.find_elements_by_xpath('//div[@class=\"salaries one-line sbold-list-header\"]')\n",
    "for i in experience_tag:\n",
    "    experience_required.append(i.text)\n",
    "    \n",
    "# Minimum salary\n",
    "salary = driver.find_elements_by_xpath('//div[@class=\"results-body\"]/div/div[2]')\n",
    "salary = [i.text.split('\\n') for i in salary]\n",
    "\n",
    "for i in salary:\n",
    "    average_salary.append(i[0])\n",
    "    minimum_salary.append(i[1])\n",
    "    maximum_salary.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "27ab6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "45e06ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data dictionary\n",
    "Data_dict = {\n",
    "'company_name' : company_name, \n",
    "'total_salary_record' : total_salary_record, \n",
    "'average_salary' : average_salary, \n",
    "'minimum_salary' : minimum_salary, \n",
    "'maximum_salary' : maximum_salary, \n",
    "'experience_required' : experience_required\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c11713b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>total_salary_record</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>minimum_salary</th>\n",
       "      <th>maximum_salary</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>(791 Salaries)</td>\n",
       "      <td>₹ 7.7L</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 16.0L</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>(478 Salaries)</td>\n",
       "      <td>₹ 12.6L</td>\n",
       "      <td>₹ 5.5L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>(381 Salaries)</td>\n",
       "      <td>₹ 13.2L</td>\n",
       "      <td>₹ 5.3L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>2-12 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>(304 Salaries)</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>2-10 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>(297 Salaries)</td>\n",
       "      <td>₹ 8.6L</td>\n",
       "      <td>₹ 4.6L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>2-8 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>(221 Salaries)</td>\n",
       "      <td>₹ 9.1L</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>2-8 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>(217 Salaries)</td>\n",
       "      <td>₹ 7.8L</td>\n",
       "      <td>₹ 4.1L</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "      <td>2-13 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>(213 Salaries)</td>\n",
       "      <td>₹ 9.7L</td>\n",
       "      <td>₹ 4.5L</td>\n",
       "      <td>₹ 18.2L</td>\n",
       "      <td>2-9 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>(163 Salaries)</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "      <td>₹ 7.0L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>1-7 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>(151 Salaries)</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 9.7L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-6 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        company_name total_salary_record average_salary minimum_salary  \\\n",
       "0                TCS      (791 Salaries)         ₹ 7.7L         ₹ 4.5L   \n",
       "1          Accenture      (478 Salaries)        ₹ 12.6L         ₹ 5.5L   \n",
       "2                IBM      (381 Salaries)        ₹ 13.2L         ₹ 5.3L   \n",
       "3          Cognizant      (304 Salaries)         ₹ 9.8L         ₹ 5.0L   \n",
       "4          Capgemini      (297 Salaries)         ₹ 8.6L         ₹ 4.6L   \n",
       "5            Infosys      (221 Salaries)         ₹ 9.1L         ₹ 4.5L   \n",
       "6      Tech Mahindra      (217 Salaries)         ₹ 7.8L         ₹ 4.1L   \n",
       "7              Wipro      (213 Salaries)         ₹ 9.7L         ₹ 4.5L   \n",
       "8           Deloitte      (163 Salaries)        ₹ 13.6L         ₹ 7.0L   \n",
       "9  Fractal Analytics      (151 Salaries)        ₹ 15.7L         ₹ 9.7L   \n",
       "\n",
       "  maximum_salary experience_required  \n",
       "0        ₹ 16.0L         2-9 yrs exp  \n",
       "1        ₹ 23.0L         2-9 yrs exp  \n",
       "2        ₹ 25.0L        2-12 yrs exp  \n",
       "3        ₹ 18.0L        2-10 yrs exp  \n",
       "4        ₹ 15.0L         2-8 yrs exp  \n",
       "5        ₹ 24.0L         2-8 yrs exp  \n",
       "6        ₹ 16.5L        2-13 yrs exp  \n",
       "7        ₹ 18.2L         2-9 yrs exp  \n",
       "8        ₹ 24.0L         1-7 yrs exp  \n",
       "9        ₹ 23.0L         2-6 yrs exp  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "df = pd.DataFrame(Data_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b686d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
